## 1. [Jailbreak is (Mostly) Simpler Than You Think.(2025)](https://arxiv.org/pdf/2503.05264v1)
|字段|内容|
|----------|---------------------------------|
|**作者**|Mark Russinovich, Ahmed Salem.|
|**录用**|Arxiv|
|**核心贡献**|
|**代码链接**|
|**研究不足**|
|**BibTex**|
|**标签**|#Jailbreak #

## 2. [Prompt, Divide, and Conquer: Bypassing Large Language Model Safety Filters via Segmented and Distributed Prompt Processing.(2025)](https://arxiv.org/pdf/2503.21598v1)
|字段|内容|
|----------|---------------------------------|
|**作者**| Johan Wahréus, Ahmed Hussain, and Panos Papadimitratos.|
|**录用**|Arxiv|
|**核心贡献**|
|**代码链接**|
|**研究不足**|
|**BibTex**|
|**标签**|# 

## 3. [Formalizing and Benchmarking Prompt Injection Attacks and Defenses.(2024)](https://www.usenix.org/system/files/usenixsecurity24-liu-yupei.pdf)
|字段|内容|
|----------|---------------------------------|
|**作者**|  Yupei Liu, Yuqi Jia, Runpeng Geng, et al.|
|**录用**|33rd USENIX Security|
|**核心贡献**|
|**代码链接**|
|**研究不足**|
|**BibTex**|
|**标签**|# 

## 4. [Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection.(2024)](https://arxiv.org/pdf/2408.03554v1)
|字段|内容|
|----------|---------------------------------|
|**作者**|  Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, et al.|
|**录用**|NAACL(SRW) 2024|
|**核心贡献**|
|**代码链接**|
|**研究不足**|
|**BibTex**|
|**标签**|# 

## 5. [Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection.(2024)](https://arxiv.org/pdf/2408.03554v1)
|字段|内容|
|----------|---------------------------------|
|**作者**|  Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, et al.|
|**录用**|NAACL(SRW) 2024|
|**核心贡献**|
|**代码链接**|
|**研究不足**|
|**BibTex**|
|**标签**|# 
